"_id","slug","title","summary","pageUrl","author","authorSlug","karma","voteCount","commentsCount","postedAt","wordCount"
"abc123def456","example-post-1","Introduction to AI Alignment","This post provides an overview of AI alignment research, discussing the importance of ensuring that artificial intelligence systems behave in accordance with human values and intentions.","https://www.alignmentforum.org/posts/abc123def456/example-post-1","John Smith","john-smith","42","15","8","2024-01-15T10:30:00.000Z","2500"
"xyz789ghi012","mesa-optimization","Risks from Learned Optimization","An exploration of mesa-optimization and the potential risks that arise when learned models develop their own internal optimization processes that may not align with the base objective.","https://www.alignmentforum.org/posts/xyz789ghi012/mesa-optimization","Alice Johnson","alice-johnson","87","32","12","2024-02-20T14:15:00.000Z","4200"
"def456jkl789","agent-foundations","Agent Foundations for Alignment","Discussion of foundational questions in decision theory and logical uncertainty as they relate to building aligned AI systems.","https://www.alignmentforum.org/posts/def456jkl789/agent-foundations","Bob Wilson","bob-wilson","56","21","5","2024-03-10T09:45:00.000Z","3100"
"mno123pqr456","interpretability-techniques","Mechanistic Interpretability Progress","Recent advances in understanding neural network internals through mechanistic interpretability, including circuit analysis and feature visualization techniques.","https://www.alignmentforum.org/posts/mno123pqr456/interpretability-techniques","Carol Davis","carol-davis","103","45","18","2024-04-05T16:20:00.000Z","5600"
"stu789vwx012","value-learning","The Challenge of Value Learning","Examining the difficulties in learning human values from observations and feedback, including problems with proxy goals and distributional shift.","https://www.alignmentforum.org/posts/stu789vwx012/value-learning","David Lee","david-lee","71","28","9","2024-05-12T11:30:00.000Z","3800"
